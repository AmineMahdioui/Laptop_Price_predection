{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laptop price predictor \n",
    "In this note book we will make a predictor to predict the price of a laptop giving some characteristics. In this project we will perform a lot of preprocessing and exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15220/2981047466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"laptop_data.csv\",encoding='latin-1')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 11 characteristics on this dataset, but some of them are really noicy, we will deal with them in the EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get some more information about this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a near perfect dataset, its awsome for academic research and to get some knowledge on how things work, the only problem is that you rarely come across data like this as it usually needs to be cleaned and processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the unique values that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col!='Price_euros':\n",
    "        print(f'{col} colum has {df[col].unique().size} unique elements'+'__'*20,f'\\nUnique values in {col}:\\n {df[col].unique()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we can observe; `Ram`, `Memory` and `Weight` are numerical data but have a unit attached, lets fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ram']=df['Ram'].str.replace('GB','')\n",
    "df['Ram']=df['Ram'].astype('int32')\n",
    "df=df.rename(columns={\"Ram\": \"Ram (GB)\"})\n",
    "df['Weight']=df['Weight'].str.replace('kg','')\n",
    "df['Weight']=df['Weight'].astype('float64')\n",
    "\n",
    "df=df.rename(columns={\"Weight\": \"Weight (kg)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['Inches','Ram (GB)']:\n",
    "       plt.figure(figsize=(15,7))\n",
    "       sn.countplot(x=variable,data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs tell us that people prefere laptops with 15.6\" displays, and laptops with 8GB of Ram are the most bought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a plot the Price and weight counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.displot(df['Price_euros'])\n",
    "plt.plot([df['Price_euros'].mean(), df['Price_euros'].mean()], [160, 0],color='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.displot(np.log1p(df['Price_euros']),kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.displot(df['Weight (kg)'])\n",
    "plt.plot([df['Weight (kg)'].mean(), df['Weight (kg)'].mean()], [180, 0],color='red' ,linewidth=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observer that weight is unevenly spread so the mean doesn't give a useful information, we can see that this data has a some laptops whos weight is more than 4kg but are still sold, we can probably say that these laptops are the workstation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical=['Company', 'TypeName', 'OpSys']\n",
    "\n",
    "for variable in Categorical:\n",
    "       plt.figure(figsize=(20,7))\n",
    "       sn.countplot(x=variable,data = df, order =df[variable].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these graphs we can see that windows 10 is the most popular OS in the dataset. We can also observe that Dell and Lenovo are fighting for the most popular brand, notebooks are the most popular type sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore more about each company and their prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.xticks(rotation=20)\n",
    "sn.barplot(x = df['Company'],y = df['Price_euros'],order=df['Company'].value_counts().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that Razor product have the most variation in price; peaking at 42244.11 MAD and reaching a bottom at 7127.26 MAD with a mean of 23176.72 MAD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the price variation based on laptop type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sn.countplot(x=df['TypeName'],order=df['TypeName'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "x = df.groupby(['TypeName']).Price_euros.max().sort_values().keys()\n",
    "sn.barplot(x = 'TypeName',y= 'Price_euros',data=df,order=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks have the least amount of variation in price compared to other laptop types, this is probably a results from the high number of notebooks and competitors in the market.\n",
    "Also the high price of workstation and the low number of units sold shows that workstations are more of a niche product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep dive to `ScreenResolution` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScreenResolution'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column has three type of data in it:\n",
    "- _TouchScreen_,\n",
    "- _display panel_ (IPS or TN Panels)\n",
    "- and _Max Screen Resolution_ (i.e. Full HD 2560x1440 ...).\n",
    "\n",
    "We need to separate this information into different columns. To do that we will one-hot encode some of this data, meaning we will convert each categorical (Touchscreen and Display) value into a new categorical column and assign a binary value of 'Yes' or 'No', for `TouchScreen` and 'TN' or 'IPS' for display panel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Starting with _TouchScreen_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TouchScreen\"]=df['ScreenResolution'].apply(lambda x:'Yes' if 'Touchscreen' in x else 'No')\n",
    "df['ScreenResolution']=df['ScreenResolution'].replace(regex={r\"/* *Touchscreen /*\":\"\"})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x='TouchScreen',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see most laptops in this dataset don't have a TouchScreen, just 192 have this functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.barplot(x = 'TouchScreen',y= 'Price_euros',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price of laptops with touchscreen is subjected to alot of variation avreging at 10009.37, in contrast to normal ones that have an average price of about 7753.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let see how each type of df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x=\"TypeName\", hue=\"TouchScreen\", data=df)\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df['TouchScreen'], columns=df['TypeName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see most of the laptops that have a Touchscreen are 2 in 1 Convertible, we can also see the most popular laptop type don't usual come with touch screen.\n",
    "\n",
    "We could say that Touchscreen are mostly a luxury for laptop users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the display panel we will asign 1 to observations with IPS panles and 0 to TN panels we can flip them it doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Display panel\"]=df['ScreenResolution'].apply(lambda x:'IPS' if 'IPS' in x else 'TN')\n",
    "df['ScreenResolution']=df['ScreenResolution'].replace(regex={r\"IPS Panel.[Retina Display ]*\":\"\"})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we at it lets also clean the `ScreenResolution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScreenResolution']=df['ScreenResolution'].replace(regex={r\"(4K)?[^0-9^x]*\":\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x='Display panel',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most laptops in this dataset dont have IPS panel but TN ones insted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.barplot(x = 'Display panel',y= 'Price_euros',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPS display panels are more expencive than TN panels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x=\"TypeName\", hue=\"Display panel\", data=df)\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df['Display panel'], columns=df['TypeName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that most Notebooks and netbooks laptop types dont use TN panel probably because of the high-price, more than half of 2 in 1 convertible laptops use IPS panels, similarly for workstations, ultrabooks and gaming laptops, close to half of them have IPS, this is logical as these panel provide better view from an angel compared to TN counterpart so they are more of a premium adition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ScreenResolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScreenResolution'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sn.countplot(x='ScreenResolution',data=df,order=df['ScreenResolution'].value_counts().index)\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we observe that 1920x1080 (FHD) is the most popular display resolution across all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['ScreenResolution'].str.split(\"x\",expand=True)\n",
    "df['X_res']=X[0]\n",
    "df['Y_res']=X[1]\n",
    "for value in ['X_res','Y_res']:\n",
    "    df[value]=df[value].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Per Inch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel density indicates how many pixels per inch (PPI) there are on a display. The higher the pixel density, the more detailed and spacious the picture is.\n",
    "\n",
    "In contrast, displays with low pixel density will have less screen space and more pixelated image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inches and resolution give almost the same amount of information we can combine them into a single metric PixelPerInch or PPI for short its calculated like the following. At the end of the day, our goal is to improve the performance by having fewer features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    PPI = \\frac{\\sqrt{X_{resolution}^2+Y_{resolution}^2}}{inches}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ppi'] = (((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Res_value\"]=df['X_res']*df['Y_res']\n",
    "df.drop(columns = ['X_res','Y_res'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert=dict(zip(df[\"Res_value\"].value_counts().index, df[\"ScreenResolution\"].value_counts().index))\n",
    "df.pop('ScreenResolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sn.boxplot(y='Price_euros',x ='Inches',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.drop(columns = ['Inches','X_res','Y_res'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `CPU` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPU column also contains lots of information, like CPU manifactuer and model and also it's speed (GHz) with 118 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will put the CPU speed in it's own column and change its dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GHz(CPU):\n",
    "    return re.search(r'\\d?\\.?\\d(?!(?!GHz))',CPU).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GHz']=df['Cpu'].apply(get_GHz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GHz']=df['GHz'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be clustering this column, so each df will either have an one of intel processors (Intel Xeon, i3, i5, i7 or Other Intel Processor) or AMD Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processor(x):\n",
    "    match=re.search(r'Intel Core i[357]',x)\n",
    "    if match:\n",
    "        return match[0]\n",
    "    if 'xeon' in x.lower():\n",
    "        return 'Intel Xeon E3'\n",
    "    if 'intel' in x.lower():\n",
    "        return 'Other Intel Processor'\n",
    "    return 'AMD Processor'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cpu_brand']=df['Cpu'].apply(get_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the price vary with processors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('Cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x='Cpu_brand',data=df,palette='plasma',order=df['Cpu_brand'].value_counts().index)\n",
    "plt.xticks(rotation=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,10))\n",
    "x = df.groupby(['Cpu_brand']).Price_euros.median().sort_values().keys()\n",
    "sn.barplot(x='Price_euros',y='Cpu_brand',data= df,order=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xeon processors are one if the best processors Intel offers which explains their very high price we can also see that i7 and i5 processors are the most popular and better than core i3 and AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Memory'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's standardize the units and remove the decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Memory']=df['Memory'].str.replace('.0','',regex=False)\n",
    "df['Memory']=df['Memory'].str.replace('GB','')\n",
    "df['Memory']=df['Memory'].str.replace('TB','000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(mem,StorageType='HDD'):\n",
    "  if StorageType in mem.split(' '):\n",
    "    i = mem.split(' ').index(StorageType)\n",
    "    return mem.split(' ')[i-1]\n",
    "  else:\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in ['HDD', 'SSD','Flash','Hybrid']:\n",
    "    df[type]=df['Memory'].apply(lambda x: get_memory(x,StorageType=type))\n",
    "    df[type]=df[type].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pop('Memory')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gpu'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[182,'Gpu']='AMD Radeon R7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gpu(x):\n",
    "    if 'Intel' in x:\n",
    "        return 'Intel Iris Graphics' if 'Iris' in x else \"Intel HD Graphics\"\n",
    "    if  'AMD' in x:\n",
    "        match = re.search(r'R[579X]',x)\n",
    "        if match:\n",
    "            return 'AMD Radeon '+match.group()\n",
    "        if 'FirePro' in x:\n",
    "            return 'AMD FirePro'\n",
    "        else:\n",
    "            return \"Other AMD Radeon\"\n",
    "    # if not AMD or Intel then its Nvidia\n",
    "    if 'Nvidia' in x:\n",
    "        if 'Quadro' in x:\n",
    "            return 'Nvidia Quadro'\n",
    "        if 'GTX' in x:\n",
    "            return 'Nvidia GeForce GTX'\n",
    "        else:\n",
    "            return 'Nvidia GeForce GT'\n",
    "    return 'Other Gpu'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gpu_model']=df['Gpu'].apply(get_Gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,7))\n",
    "x = df.groupby(['Gpu_model']).Price_euros.median().sort_values().keys()\n",
    "sn.boxplot(x='Price_euros',y='Gpu_model',data= df,order=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,3,figsize=(25,20))\n",
    "companies=df[\"TypeName\"].unique()\n",
    "j=i=0\n",
    "for company in companies[0:12]:\n",
    "  data = df.groupby([\"TypeName\",\"Gpu_model\"]).count()['laptop_ID'][company]   \n",
    "  data.plot.pie (autopct=\"%.1f%%\",ax=ax[i][j])\n",
    "  ax[i][j].set_title(company)\n",
    "  j+=1\n",
    "  if j%3 == 0:\n",
    "    i+=1\n",
    "    j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['laptop_ID','Product','Inches', 'Gpu'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.displot(df['Price_euros'],kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.displot(np.log(df['Price_euros']),kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price_euros']=df.pop('Price_euros')\n",
    "plt.figure(figsize=(20,12))\n",
    "sn.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Price_euros'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that have prepared our data and hold a better understanding of the dataset. let’s get started with Machine learning modeling! and finding the best algorithm with the best hyperparameters to achieve maximum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's load the libraries that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sl\n",
    "from sklearn.compose import ColumnTransformer,make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression,Ridge,BayesianRidge,SGDRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error,max_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getName(x):\n",
    "    return re.search(r\"\\w*(?!(?!'>))\",str(x)).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.log(df['Price_euros'])\n",
    "X=df.loc[:, df.columns != 'Price_euros']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapper = {i:value for i,value in enumerate(X_train.columns)}\n",
    "mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the preprocessing pipelines for both numeric and categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = make_column_selector(dtype_include=np.number)\n",
    "cat_features = make_column_selector(dtype_exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_features = ['Ram (GB)','Weight (kg)','ppi','Res_value','GHz','HDD','SSD','Flash','Hybrid']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "#categorical_features = ['Company','TypeName','OpSys','Cpu_brand','Gpu_model']\n",
    "categorical_transformer = OneHotEncoder(sparse=False,drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, cat_features),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(preprocessor.fit_transform(X),y,test_size=0.15,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_pipe(mdl):\n",
    "    return Pipeline(steps=[(\"Reg\", mdl())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After appending a regression model we have a full prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models=[LinearRegression,Ridge,SGDRegressor,DecisionTreeRegressor,RandomForestRegressor,GradientBoostingRegressor,\n",
    "#        SVR,BayesianRidge,LGBMRegressor,XGBRegressor,AdaBoostRegressor,CatBoostRegressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(md):\n",
    "    for score_type,X,y in zip(['+ Training accuracy','+ Test accuracy'],[X_train,X_test],[y_train,y_test]):\n",
    "        print(score_type)\n",
    "        y_pred = md.predict(X)\n",
    "        print('|            R2 Score: {:.3}%'.format(r2_score(y,y_pred)*100))\n",
    "        print('| Mean Absolute Error: {:.3}'.format(mean_squared_error(y,y_pred)))\n",
    "        print('|           Max Error: {:.3}'.format(max_error(y,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    md=Model_pipe(model)\n",
    "    md.fit(X_train,y_train)\n",
    "    print('\\n------ {} ------'.format(getName(model)))\n",
    "    scores(md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinary least squares Linear Regression.**\n",
    "\n",
    "$\\mathbf {y}$ is a $n\\times 1$, ($1303\\times 1$ in our case), vectors of the response variables, and ${\\mathrm  {X}}$ is an $n\\times p$, ($1303\\times 16$), matrix of regressors, whose $i$ th row is $\\mathbf {x} _{i}$ and contains the $i-th$ observations on all the explanatory variables. In a linear regression model, the response variable, $y_{i}$, is a linear function of the regressors:\n",
    "$$\n",
    "{\\displaystyle \\mathbf {y} =\\mathrm {X} {\\boldsymbol {\\beta }}+{\\boldsymbol {\\varepsilon }},\\,}\n",
    "$$\n",
    "where ${\\boldsymbol {\\beta }}$ is a $16\\times 1$ vector of unknown parameters and $\\boldsymbol{\\varepsilon}$ is a $1303\\times 1$ vectors of the errors of the $n$ observations.\n",
    "\n",
    "`LinearRegression` fits a linear model with coefficients $ \\boldsymbol {\\beta } = ({\\beta }_1, …, {\\beta }_p) $ to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "$$\n",
    "\\sum _{i=1}^{1303}{\\biggl |}y_{i}-\\sum _{j=1}^{16}X_{ij}\\beta _{j}{\\biggr |}^{2}={\\bigl \\|}\\mathbf {y} -\\mathrm {X} {\\boldsymbol {\\beta }}{\\bigr \\|}^{2}_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(LinearRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = Model_pipe(GradientBoostingRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_GBR = {\n",
    "    'Reg__learning_rate': [.01,.03, 0.05, .07],\n",
    "    'Reg__subsample'    : [0.7, 0.5, 0.2, 0.1],\n",
    "    'Reg__n_estimators' : [1000],\n",
    "    'Reg__max_depth'    : [4,6,8,10,12],\n",
    "    'Reg' : [GradientBoostingRegressor()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GBR = GridSearchCV(GBR,param_GBR,n_jobs=-1,scoring='r2',error_score='raise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid_GBR.best_score_)\n",
    "print(grid_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter (CV score=0.905):\n",
    "{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 1000, 'subsample': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(grid_GBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(XGBRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_XGBR = {\n",
    "    'Reg__learning_rate'    : [.01,.03, 0.05, .07],\n",
    "    'Reg__subsample'        : [0.7, 0.5, 0.2, 0.1],\n",
    "    'Reg__n_estimators'     : [1000],\n",
    "    'Reg__max_depth'        : [2,4,6,8,10],\n",
    "    'Reg'                   : [XGBRegressor()]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = Model_pipe(XGBRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGBR = GridSearchCV(XGBR,param_XGBR,n_jobs=-1,scoring='r2',error_score='raise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGBR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid_XGBR.best_score_)\n",
    "print(grid_XGBR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(grid_XGBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't have Hyperparameters to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMR=Model_pipe(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_SVMR={\n",
    "            'Reg__C': [1.1, 5.4, 170, 1001],\n",
    "            'Reg__epsilon': [0.0003, 0.007, 0.0109, 0.019, 0.14, 0.05, 8, 0.2, 3, 2, 7],\n",
    "            'Reg__gamma': [0.7001, 0.008, 0.001, 3.1, 1, 1.3, 5],\n",
    "            'Reg' : [SVR()]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SVMR = GridSearchCV(SVMR,param_SVMR,n_jobs=60,scoring='r2',error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SVMR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid_SVMR.best_score_)\n",
    "print(grid_SVMR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(grid_SVMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR=Model_pipe(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_DTR={\n",
    "    \"Reg__criterion\": [\"mse\", \"mae\"],\n",
    "    \"Reg__min_samples_split\": [10, 20, 40],\n",
    "    \"Reg__max_depth\": [2, 6, 8],\n",
    "    \"Reg__min_samples_leaf\": [20, 40, 100],\n",
    "    \"Reg__max_leaf_nodes\": [5, 20, 100],\n",
    "    \"Reg\" : [DecisionTreeRegressor()]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_DTR = GridSearchCV(DTR,param_DTR,n_jobs=60,scoring='r2',error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_DTR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid_DTR.best_score_)\n",
    "print(grid_DTR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(grid_DTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR=Model_pipe(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_RFR={\n",
    "    \"Reg__criterion\": [\"mse\", \"mae\"],\n",
    "    \"Reg__max_depth\": [2, 6, 8],\n",
    "    \"Reg__min_samples_leaf\": [20, 40, 100],\n",
    "    \"Reg__max_leaf_nodes\": [5, 20, 100],\n",
    "    \"Reg__min_samples_split\": [10, 20, 40],\n",
    "    \"Reg\" : [RandomForestRegressor()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RFR = GridSearchCV(RFR,param_RFR,n_jobs=60,scoring='r2',error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RFR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % grid_RFR.best_score_)\n",
    "print(grid_RFR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores(grid_RFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next step is to know how well our models performes for making predictions on the unknown test set. There are various metrics to check that. However, mean absolute error, mean squared error, and root mean squared error are three of the most common metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=Model_pipe(LinearRegression)\n",
    "md.fit(X_train,y_train)\n",
    "print('\\n------ {} ------'.format(getName(md)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9542dd7b953ad8a15b001f77d82648cfda59701cf2c2b565b7c59e3c6c6ed16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
